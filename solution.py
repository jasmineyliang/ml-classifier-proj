# -*- coding: utf-8 -*-
"""

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VX4NsDIcdYtW3vMvBwmRBQQ6tRR8v1ZG
"""

import math
import numpy as np 

THETA = 0.5


class Tree(object):

    def __init__(self, feature=None, ys=[], left=None, right=None):
        self.feature = feature
        self.ys = ys
        self.left = left
        self.right = right

    @property
    def size(self):
        size = 1
        if type(self.left) == int:
            size += 1
        else:
            size += self.left.size
        if type(self.right) == int:
            size += 1
        else:
            size += self.right.size
        return size

    @property
    def depth(self):
        left_depth = 1 if type(self.left) == int else self.left.depth
        right_depth = 1 if type(self.right) == int else self.right.depth
        return max(left_depth, right_depth)+1


def entropy(data):
    """Compute entropy of data.

    Args:
        data: A list of data points [(x_0, y_0), ..., (x_n, y_n)]

    Returns:
        entropy of data (float)
    """
    ### YOUR CODE HERE
    wise  = 0;
    for i in range (len(data)):
      if data[i][1] == 0:
        wise = wise +1
    

    A=0
    B=0
    A = wise/(len(data))
    B = ((len(data))-wise)/(len(data))
    entropy  = (-(A)*math.log2(A)) - ((B)* math.log2(B))
     
    return entropy
    ### END YOUR CODE


def gain(data, feature):
    """Compute the gain of data of splitting by feature.

    Args:
        data: A list of data points [(x_0, y_0), ..., (x_n, y_n)]
        feature: index of feature to split the data

    Returns:
        gain of splitting data by feature
    """
    ### YOUR CODE HERE

    # please call entropy to compute entropy

    having = 0
    have_wise = 0
    haven_wise =0
    yes = []
    no=[]
    for i in range (len(data)):
      if data[i][feature]==1:
        yes.append(data[i])
        having = having +1
      else:
        no.append(data[i])

      
    
    E = entropy(data)
    gain = E-((having/(len(data)))*(entropy(yes)))-(((len(data))-having)/(len(data)))*(entropy(no))
    return gain
    ### END YOUR CODE


def get_best_feature(data):
    """Find the best feature to split data.

    Args:
        data: A list of data points [(x_0, y_0), ..., (x_n, y_n)]

    Returns:
        index of feature to split data
    """

    ### YOUR CODE HERE

    best_index = 0
    M = len(data[0][0])
    max_gain =0
    for i in range (M-1):
      if gain(data,i) > max_gain: 
        max_gain = gain(data,i)
        best_feature = i
    return best_feature
    # please call gain to compute gain

    ### END YOUR CODE


def build_tree(data):
    ys = {}
    for x, y in data:
        ys[y] = ys.get(y, 0) + 1
    if len(ys) == 1:
        return list(ys)[0]
    feature = self.get_best_feature(data)
    
    ### YOUR CODE HERE

    # please split your data with feature and build two sub-trees
    # by calling build_tree recursively
    data_left = []
    data_right = []
    for i in range (len(data)):
      if data[i][get_best_feature(data)]==1:
        data_left = data_left. append data[i]
      else :
        data_right = data_right. append data[i]

    left_tree = build_tree(data_left)      
    right_tree = build_tree(data_right)

    # Use THETA to split the continous feature

    ### END YOUR CODE
    return Tree(feature, ys, left_tree, right_tree)


def test_entry(tree, entry):
    x, y = entry
    if type(tree) == int:
        return tree, y
    if x[tree.feature] < THETA:
        return test_entry(tree.left, entry)
    else:
        return test_entry(tree.right, entry)


def test_data(tree, data):
    count = 0
    for d in data:
        y_hat, y = test_entry(tree, d)
        count += (y_hat == y)
    return round(count/float(len(data)), 4)


def prune_tree(tree, data):
    """Find the best feature to split data.

    Args:
        tree: a decision tree to prune
        data: A list of data points [(x_0, y_0), ..., (x_n, y_n)]

    Returns:
        a pruned tree
    """
    ### YOUR CODE HERE

    # please call test_data to obtain validation error
    # please call prune_tree recursively for pruning tree
        ### END YOUR CODE